{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import PIL.Image\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator, img_to_array\n",
    "from keras.layers import  *\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing import image\n",
    "from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of train data : (5286, 6)\n",
      "Shape of test data : (624, 6)\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('/Users/kos/Desktop/test data/ChestRay/Chest_xray_Corona_Metadata.csv')\n",
    "train_df.dropna(how='all')\n",
    "train_df.fillna('unknown', inplace=True)\n",
    "train_data = train_df[train_df['Dataset_type'] == 'TRAIN']\n",
    "test_data = train_df[train_df['Dataset_type'] == 'TEST']\n",
    "assert train_data.shape[0] + test_data.shape[0] == train_df.shape[0]\n",
    "print(f\"Shape of train data : {train_data.shape}\")\n",
    "print(f\"Shape of test data : {test_data.shape}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [],
   "source": [
    "test_img_dir = '/Users/kos/Desktop/test data/ChestRay/Coronahack-Chest-XRay-Dataset' \\\n",
    "               '/Coronahack-Chest-XRay-Dataset/test'\n",
    "train_img_dir = '/Users/kos/Desktop/test data/ChestRay/Coronahack-Chest-XRay-Dataset' \\\n",
    "                '/Coronahack-Chest-XRay-Dataset/train'\n",
    "\n",
    "sample_train_images = list(os.walk(train_img_dir))[0][2][:8]\n",
    "sample_train_images = list(map(lambda x: os.path.join(train_img_dir, x), sample_train_images))\n",
    "\n",
    "sample_test_images = list(os.walk(test_img_dir))[0][2][:8]\n",
    "sample_test_images = list(map(lambda x: os.path.join(test_img_dir, x), sample_test_images))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "# remove Pnuemonia with unknown value\n",
    "final_train_data = train_data[(train_data['Label'] == 'Normal') |\n",
    "                              ((train_data['Label'] == 'Pnemonia') &\n",
    "                               (train_data['Label_2_Virus_category'] == 'COVID-19'))]\n",
    "\n",
    "# add a target and class feature\n",
    "final_train_data['class'] = final_train_data.Label.apply(lambda x: 'negative' if x == 'Normal' else 'positive')\n",
    "test_data['class'] = test_data.Label.apply(lambda x: 'negative' if x == 'Normal' else 'positive')\n",
    "\n",
    "final_train_data['target'] = final_train_data.Label.apply(lambda x: 0 if x=='Normal' else 1)\n",
    "test_data['target'] = test_data.Label.apply(lambda x: 0 if x == 'Normal' else 1)\n",
    "# get the important features\n",
    "final_train_data = final_train_data[['X_ray_image_name', 'class', 'target', 'Label_2_Virus_category']]\n",
    "final_test_data = test_data[['X_ray_image_name', 'class', 'target']]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20it [00:00, 102.87it/s]             \n",
      "20it [00:00, 153.21it/s]             \n",
      "20it [00:00, 147.28it/s]             \n",
      "20it [00:00, 182.32it/s]             \n",
      "20it [00:00, 183.62it/s]             \n",
      "20it [00:00, 176.98it/s]             \n",
      "20it [00:00, 180.11it/s]             \n",
      "20it [00:00, 163.44it/s]             \n",
      "20it [00:00, 179.35it/s]             \n",
      "20it [00:00, 175.84it/s]             \n",
      "20it [00:00, 185.72it/s]             \n",
      "20it [00:00, 159.33it/s]             \n",
      "20it [00:00, 188.35it/s]             \n",
      "20it [00:00, 100.89it/s]             \n",
      "20it [00:00, 161.25it/s]             \n",
      "20it [00:00, 164.86it/s]             \n",
      "20it [00:00, 192.22it/s]             \n",
      "20it [00:00, 186.28it/s]             \n",
      "20it [00:00, 175.09it/s]             \n",
      "20it [00:00, 172.41it/s]             \n",
      "20it [00:00, 151.99it/s]             \n",
      "20it [00:00, 166.62it/s]             \n",
      "20it [00:00, 186.70it/s]             \n",
      "20it [00:00, 180.28it/s]             \n",
      "20it [00:00, 192.60it/s]             \n",
      "20it [00:00, 181.38it/s]             \n",
      "20it [00:00, 188.78it/s]             \n",
      "20it [00:00, 188.26it/s]             \n",
      "20it [00:00, 194.98it/s]             \n",
      "20it [00:00, 196.66it/s]             \n",
      "20it [00:00, 180.97it/s]             \n",
      "20it [00:00, 186.73it/s]             \n",
      "20it [00:00, 195.59it/s]             \n",
      "20it [00:00, 195.40it/s]             \n",
      "20it [00:00, 182.42it/s]             \n",
      "20it [00:00, 178.72it/s]             \n",
      "20it [00:00, 182.78it/s]             \n",
      "20it [00:00, 173.18it/s]             \n",
      "20it [00:00, 180.16it/s]             \n",
      "20it [00:00, 179.78it/s]             \n",
      "20it [00:00, 170.26it/s]             \n",
      "20it [00:00, 194.54it/s]             \n",
      "20it [00:00, 196.37it/s]             \n",
      "20it [00:00, 192.70it/s]             \n",
      "20it [00:00, 187.07it/s]             \n",
      "20it [00:00, 190.60it/s]             \n",
      "20it [00:00, 186.83it/s]             \n",
      "20it [00:00, 187.24it/s]             \n",
      "20it [00:00, 187.34it/s]             \n",
      "20it [00:00, 187.75it/s]             \n",
      "20it [00:00, 177.24it/s]             \n",
      "20it [00:00, 181.82it/s]             \n",
      "20it [00:00, 181.10it/s]             \n",
      "20it [00:00, 180.11it/s]             \n",
      "20it [00:00, 186.22it/s]             \n",
      "20it [00:00, 192.45it/s]             \n",
      "20it [00:00, 194.97it/s]             \n",
      "20it [00:00, 190.49it/s]             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5221    None\n",
      "5222    None\n",
      "5223    None\n",
      "5224    None\n",
      "5225    None\n",
      "5226    None\n",
      "5227    None\n",
      "5228    None\n",
      "5229    None\n",
      "5230    None\n",
      "5237    None\n",
      "5238    None\n",
      "5239    None\n",
      "5240    None\n",
      "5242    None\n",
      "5243    None\n",
      "5244    None\n",
      "5245    None\n",
      "5246    None\n",
      "5247    None\n",
      "5248    None\n",
      "5249    None\n",
      "5250    None\n",
      "5251    None\n",
      "5252    None\n",
      "5253    None\n",
      "5254    None\n",
      "5255    None\n",
      "5256    None\n",
      "5257    None\n",
      "5258    None\n",
      "5259    None\n",
      "5260    None\n",
      "5261    None\n",
      "5262    None\n",
      "5263    None\n",
      "5264    None\n",
      "5265    None\n",
      "5266    None\n",
      "5267    None\n",
      "5268    None\n",
      "5269    None\n",
      "5270    None\n",
      "5271    None\n",
      "5272    None\n",
      "5273    None\n",
      "5274    None\n",
      "5275    None\n",
      "5276    None\n",
      "5277    None\n",
      "5278    None\n",
      "5279    None\n",
      "5280    None\n",
      "5281    None\n",
      "5282    None\n",
      "5283    None\n",
      "5284    None\n",
      "5285    None\n",
      "Name: X_ray_image_name, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "  shear_range=0.2,\n",
    "  zoom_range=0.2,\n",
    ")\n",
    "\n",
    "def read_img(filename, size, path):\n",
    "    img = image.load_img(os.path.join(path, filename), target_size=size)\n",
    "    img = img_to_array(img) / 255\n",
    "    return img\n",
    "\n",
    "\n",
    "corona_df = final_train_data[final_train_data['Label_2_Virus_category'] == 'COVID-19']\n",
    "with_corona_augmented = []\n",
    "\n",
    "# create a function for augmentation\n",
    "def augment(name):\n",
    "    img = read_img(name, (255,255), train_img_dir)\n",
    "    i = 0\n",
    "    for batch in tqdm(datagen.flow(tf.expand_dims(img, 0), batch_size=32)):\n",
    "        with_corona_augmented.append(tf.squeeze(batch).numpy())\n",
    "        if i == 20:\n",
    "            break\n",
    "        i = i + 1\n",
    "\n",
    "\n",
    "# apply the function\n",
    "print(corona_df['X_ray_image_name'].apply(augment))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "data": {
      "text/plain": "5286    None\n5287    None\n5288    None\n5289    None\n5290    None\n        ... \n5905    None\n5906    None\n5907    None\n5908    None\n5909    None\nName: X_ray_image_name, Length: 624, dtype: object"
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_arrays = []\n",
    "final_train_data['X_ray_image_name'].apply(lambda x: train_arrays.append(read_img(x, (255, 255), train_img_dir)))\n",
    "test_arrays = []\n",
    "final_test_data['X_ray_image_name'].apply(lambda x: test_arrays.append(read_img(x, (255, 255), test_img_dir)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [],
   "source": [
    "# concatenate the training data labels and the labels for augmented images\n",
    "y_train = np.concatenate((np.int64(final_train_data['target'].values),\n",
    "                          np.ones(len(with_corona_augmented), dtype=np.int64)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "# Converting Data to tensors\n",
    "train_tensors = tf.convert_to_tensor(np.concatenate((np.array(train_arrays), np.array(with_corona_augmented))))\n",
    "test_tensors  = tf.convert_to_tensor(np.array(test_arrays))\n",
    "y_train_tensor = tf.convert_to_tensor(y_train)\n",
    "y_test_tensor = tf.convert_to_tensor(final_test_data['target'].values)\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_tensors, y_train_tensor))\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_tensors, y_test_tensor))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "BUFFER = 1000\n",
    "\n",
    "train_batches = train_dataset.shuffle(BUFFER).batch(BATCH_SIZE)\n",
    "test_batches = test_dataset.batch(BATCH_SIZE)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "# define input shape\n",
    "INPUT_SHAPE = (255,255,3)\n",
    "\n",
    "#get the pretrained model\n",
    "base_model = tf.keras.applications.ResNet50(input_shape= INPUT_SHAPE,\n",
    "                                               include_top=False,\n",
    "                                               weights='imagenet')\n",
    "\n",
    "# set the trainable method of covolution layer as false\n",
    "# why set to false?? because we don't want to mess up the pretrained weights of the model!!\n",
    "base_model.trainable = False"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "data": {
      "text/plain": "TensorShape([16, 8, 8, 2048])"
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's try to pass an image to the model to verify the output shape\n",
    "for i,l in train_batches.take(1):\n",
    "    pass\n",
    "base_model(i).shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dense(128))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation = 'sigmoid'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [],
   "source": [
    "# add an earlystopping callback to stop the training if the model is not learning anymore\n",
    "callbacks = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=2)\n",
    "\n",
    "# let's just choose adam as our optimizer, we all love adam anyway.\n",
    "model.compile(optimizer='adam',\n",
    "              loss = 'binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164/164 [==============================] - 324s 2s/step - loss: 0.2007 - accuracy: 0.9404 - val_loss: 0.8744 - val_accuracy: 0.6298\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x104c82040>"
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_batches, epochs=1, validation_data=test_batches, callbacks=[callbacks])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.93      0.65       234\n",
      "           1       0.91      0.45      0.60       390\n",
      "\n",
      "    accuracy                           0.63       624\n",
      "   macro avg       0.71      0.69      0.63       624\n",
      "weighted avg       0.76      0.63      0.62       624\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# predict the test data\n",
    "# pred = np.argmax(model.predict(np.array(test_arrays)), axis=1)\n",
    "pred = (model.predict(np.array(test_arrays)) > 0.5).astype(\"int32\")\n",
    "\n",
    "# let's print a classification report\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(classification_report(test_data['target'], pred.flatten()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}